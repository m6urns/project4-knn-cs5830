{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['disease'] = data.num.apply(lambda x: min(x,1))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "        \n",
    "    data = data.drop('num', axis=1)\n",
    "    data = data.dropna()\n",
    "\n",
    "    X = data.drop('disease', axis=1)\n",
    "    y = data['disease']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "    \n",
    "    return X_scaled_df.values, y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data('data/cleveland.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [np.sqrt(np.sum((x - x_train) ** 2)) for x_train in self.X_]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_[i] for i in k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    # def get_params(self, deep=True):\n",
    "    #     return {\"k\": self.k}\n",
    "\n",
    "    # def set_params(self, **parameters):\n",
    "    #     for parameter, value in parameters.items():\n",
    "    #         setattr(self, parameter, value)\n",
    "    #     return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, model, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Print precision, recall, and f1 score for each fold\n",
    "        print(\"Precision:\", precision_score(y_test, predictions), \"Recall:\", recall_score(y_test, predictions), \"F1:\", f1_score(y_test, predictions))\n",
    "        precisions.append(precision_score(y_test, predictions, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, predictions, zero_division=0))\n",
    "        f1_scores.append(f1_score(y_test, predictions, zero_division=0))\n",
    "    \n",
    "    return {\n",
    "        'precision': (np.mean(precisions), np.std(precisions)),\n",
    "        'recall': (np.mean(recalls), np.std(recalls)),\n",
    "        'f1': (np.mean(f1_scores), np.std(f1_scores))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8333333333333334 Recall: 0.9090909090909091 F1: 0.8695652173913043\n",
      "Precision: 1.0 Recall: 0.8461538461538461 F1: 0.9166666666666666\n",
      "Precision: 0.9375 Recall: 0.8823529411764706 F1: 0.9090909090909091\n",
      "Precision: 0.7894736842105263 Recall: 0.8333333333333334 F1: 0.8108108108108109\n",
      "Precision: 0.8095238095238095 Recall: 0.85 F1: 0.8292682926829268\n",
      "Precision: 0.8571428571428571 Recall: 0.9230769230769231 F1: 0.8888888888888888\n",
      "Precision: 0.7272727272727273 Recall: 0.6666666666666666 F1: 0.6956521739130435\n",
      "Precision: 0.7142857142857143 Recall: 0.7692307692307693 F1: 0.7407407407407407\n",
      "Precision: 0.75 Recall: 0.8181818181818182 F1: 0.782608695652174\n",
      "Precision: 0.5833333333333334 Recall: 0.7777777777777778 F1: 0.6666666666666666\n",
      "\n",
      "Mean Results for kNN:\n",
      "Precision: 0.800 (+/- 0.112)\n",
      "Recall: 0.828 (+/- 0.072)\n",
      "F1 Score: 0.811 (+/- 0.084)\n"
     ]
    }
   ],
   "source": [
    "knn = kNN(k=3)\n",
    "results = cross_validate(X, y, knn)\n",
    "print(f\"\\nMean Results for kNN:\")\n",
    "print(f\"Precision: {results['precision'][0]:.3f} (+/- {results['precision'][1]:.3f})\")\n",
    "print(f\"Recall: {results['recall'][0]:.3f} (+/- {results['recall'][1]:.3f})\")\n",
    "print(f\"F1 Score: {results['f1'][0]:.3f} (+/- {results['f1'][1]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    0.279725\n",
      "2     0.151193\n",
      "11    0.108062\n",
      "7     0.083773\n",
      "4     0.079608\n",
      "9     0.076073\n",
      "0     0.072169\n",
      "3     0.050094\n",
      "10    0.031960\n",
      "1     0.028341\n",
      "6     0.016259\n",
      "8     0.012420\n",
      "5     0.010323\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def feature_importance(X, y):\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X, y)\n",
    "    importances = dt.feature_importances_\n",
    "    return pd.Series(importances).sort_values(ascending=False)\n",
    "\n",
    "importance_results = feature_importance(X, y)\n",
    "\n",
    "print(importance_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
